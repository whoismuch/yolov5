{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-21T09:01:58.768317Z",
     "start_time": "2024-06-21T09:01:12.612598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML automatic browser login failed, please login or create a new account\n",
      "To get started with ClearML: setup your own `clearml-server`, or create a free account at https://app.clear.ml\n",
      "\n",
      "Please login to https://app.clear.ml , then press [Enter] to connect \n",
      "We cannot connect automatically (adblocker / incognito?) üòü \n",
      "Please go to https://app.clear.ml/settings/workspace-configuration \n",
      "Then press \u001B[1m\u001B[48;2;26;30;44m\u001B[37m + Create new credentials \u001B[0m \n",
      "And copy/paste your \u001B[1m\u001B[4mAccess Key\u001B[0m here:  Setting access key \n",
      "Now copy/paste your \u001B[1m\u001B[4mSecret Key\u001B[0m here:  Setting secret key \n",
      "\n",
      "\n",
      "Hurrah! ü•≥ üéä üéâ\n",
      "ü§ñ ClearML connected successfully - let's build something! üöÄ\n"
     ]
    }
   ],
   "source": [
    "import clearml\n",
    "\n",
    "clearml.browser_login()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!python train.py --img 640 --epochs 1 --data custom_dataset/custom_dataset.yaml --weights '' --cfg yolov5s.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T08:33:15.407498Z",
     "start_time": "2024-06-21T08:33:15.403894Z"
    }
   },
   "id": "46beb1eb8a2cd453",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!python train.py --img 640 --epochs 10 --data custom_dataset/custom_dataset.yaml --weights '' --cfg yolov5s.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-21T08:33:15.405316Z"
    }
   },
   "id": "41f258c54cc63977",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!python train.py --img 640 --epochs 50 --data custom_dataset/custom_dataset.yaml --weights '' --cfg yolov5s.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-21T08:33:15.406462Z"
    }
   },
   "id": "aa4d890b0f402447",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!python train.py --img 640 --epochs 3 --data test_dataset/test_dataset.yaml --weights '' --cfg yolov5s.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T08:33:15.407843Z",
     "start_time": "2024-06-21T08:33:15.407633Z"
    }
   },
   "id": "bab3778dfe1276a2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!python train.py --img 640 --epochs 100 --data test_dataset/test_dataset.yaml --weights '' --cfg yolov5s.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-21T08:33:15.408533Z"
    }
   },
   "id": "43a294a3c0a58bb0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!python train.py --img 640 --epochs 100 --data test_dataset/test_dataset.yaml --weights '' --cfg yolov5s.yaml\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-21T08:33:15.409507Z"
    }
   },
   "id": "e4c67ced1a66e2dd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!python train.py --img 640 --epochs 10 --data test_dataset/test_dataset.yaml --weights '' --cfg yolov5s.yaml\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-21T08:33:15.410868Z"
    }
   },
   "id": "edf4bd9fe246e12c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!python train.py --img 640 --epochs 3 --data coco128.yaml --weights '' --cfg yolov5s.yaml\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-21T08:33:15.411722Z"
    }
   },
   "id": "f94340f929dacfdc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-21T08:33:15.412755Z"
    }
   },
   "id": "ad2d02285d7b1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!python train.py --img 640 --epochs 3 --data custom_dataset/custom_dataset.yaml  --weights 'yolov5s.pt' --cfg yolov5s.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-21T08:33:15.413864Z"
    }
   },
   "id": "2a86fbe682c63c49",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!python train.py --img 640 --epochs 50 --data custom_dataset/custom_dataset.yaml  --weights 'yolov5s.pt' --cfg yolov5s.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-21T08:33:15.414519Z"
    }
   },
   "id": "936263309e4dda91",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!python train.py --img 640 --epochs 100 --data custom_dataset/custom_dataset.yaml  --weights 'yolov5s.pt' --cfg yolov5s.yaml\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-21T08:33:15.415355Z"
    }
   },
   "id": "820a8d94b02f9142",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!python train.py --img 640 --epochs 250 --data custom_dataset/custom_dataset.yaml  --weights 'yolov5s.pt' --cfg yolov5s.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-21T08:33:15.415784Z"
    }
   },
   "id": "154daf23e8466ee3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    " –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–µ"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67441b8798217538"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!python train.py --img 640 --epochs 10 --data custom_dataset/custom_dataset.yaml  --weights 'yolov5s.pt' --cfg yolov5s.yaml --hyp hyp/hyp.scratch-low.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-21T08:33:15.416409Z"
    }
   },
   "id": "f4826e90052ba8af",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "1 cat in train"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d3762fa4c04d433"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!python train.py --img 640 --epochs 10 --data custom_dataset/custom_dataset.yaml  --weights 'yolov5s.pt' --cfg yolov5s.yaml --hyp hyp/hyp.scratch-low.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-21T08:33:15.416948Z"
    }
   },
   "id": "d4cebd6941c5e567",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!python train.py --img 640 --epochs 50 --data custom_dataset/custom_dataset.yaml  --weights 'yolov5s.pt' --cfg yolov5s.yaml --hyp hyp/hyp.scratch-low.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-21T08:33:15.417419Z"
    }
   },
   "id": "5911115fdb6f4558",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "71e8418594831f72"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mweights=yolov5s.pt, cfg=yolov5s.yaml, data=custom_dataset/custom_dataset.yaml, hyp=hyp/hyp.scratch-low.yaml, epochs=100, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\r\n",
      "\u001B[34m\u001B[1mgithub: \u001B[0m‚ö†Ô∏è YOLOv5 is out of date by 2814 commits. Use 'git pull ultralytics master' or 'git clone https://github.com/ultralytics/yolov5' to update.\r\n",
      "YOLOv5 üöÄ e8f8ccfe Python-3.11.5 torch-2.2.1 CPU\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mhyperparameters: \u001B[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0\r\n",
      "\u001B[34m\u001B[1mComet: \u001B[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\r\n",
      "ClearML Task: created new task id=a27beb7541524ebba8192ca617d8f7ad\r\n",
      "ClearML results page: https://app.clear.ml/projects/40862dec8602479f8c193e1bac487205/experiments/a27beb7541524ebba8192ca617d8f7ad/output/log\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "\r\n",
      "                 from  n    params  module                                  arguments                     \r\n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \r\n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \r\n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \r\n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \r\n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \r\n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \r\n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \r\n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \r\n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \r\n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \r\n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \r\n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \r\n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \r\n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \r\n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \r\n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \r\n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \r\n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \r\n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \r\n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \r\n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \r\n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \r\n",
      " 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\r\n",
      "YOLOv5s summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\r\n",
      "\r\n",
      "Transferred 348/349 items from yolov5s.pt\r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0), 60 bias\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov5/\u001B[0m\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mAutoAnchor: \u001B[0m3.94 anchors/target, 0.989 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\r\n",
      "Plotting labels to runs/train/exp23/labels.jpg... \r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 8 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/train/exp23\u001B[0m\r\n",
      "Starting training for 100 epochs...\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "       0/99         0G    0.04622    0.03529    0.01086         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.979          1      0.995      0.874\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "       1/99         0G    0.04553    0.03488    0.01059         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.992      0.995      0.842\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "       2/99         0G    0.04475      0.034   0.009912         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.988      0.995      0.842\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "       3/99         0G     0.0436    0.03265   0.008933         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.984      0.995      0.842\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "       4/99         0G    0.04195    0.03097   0.007922         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.981      0.995      0.816\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "       5/99         0G    0.03997    0.02914   0.006991         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.994          1      0.995      0.797\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "       6/99         0G    0.03805    0.02733   0.006157         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.995          1      0.995      0.816\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "       7/99         0G    0.03644    0.02563   0.005423         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.998          1      0.995      0.821\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "       8/99         0G    0.03516    0.02403   0.004808         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.999          1      0.995      0.821\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "       9/99         0G    0.03392    0.02262   0.004278         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.999      0.995      0.821\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      10/99         0G    0.03265     0.0214   0.003804         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.996      0.995      0.816\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      11/99         0G    0.03139    0.02036   0.003358         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.994      0.995      0.804\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      12/99         0G    0.03024    0.01945   0.002941         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.992      0.995      0.816\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      13/99         0G    0.02916    0.01867   0.002571         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.989      0.995      0.827\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      14/99         0G    0.02846    0.01799   0.002272         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.987      0.995      0.748\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      15/99         0G    0.02827    0.01737   0.002052         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.985      0.995      0.827\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      16/99         0G    0.02782    0.01672   0.001898         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.984      0.995      0.748\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      17/99         0G    0.02807    0.01623   0.001779         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.984      0.995      0.748\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      18/99         0G    0.02807    0.01623   0.001779         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.984      0.995      0.872\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      19/99         0G    0.02823    0.01568   0.001689         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.984      0.995      0.872\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      20/99         0G    0.02823    0.01568   0.001689         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.983      0.995      0.761\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      21/99         0G    0.02839     0.0152   0.001603         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.983      0.995      0.761\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      22/99         0G    0.02839     0.0152   0.001603         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.982      0.995      0.837\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      23/99         0G     0.0291    0.01468   0.001544         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.982      0.995      0.837\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      24/99         0G     0.0291    0.01468   0.001544         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1       0.98      0.995      0.696\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      25/99         0G    0.02914    0.01426   0.001481         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1       0.98      0.995      0.696\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      26/99         0G    0.02914    0.01426   0.001481         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.981      0.995      0.895\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      27/99         0G    0.02887    0.01379   0.001442         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.981      0.995      0.895\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      28/99         0G    0.02887    0.01379   0.001442         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.979      0.995      0.737\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      29/99         0G    0.02954    0.01359   0.001396         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.979      0.995      0.737\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      30/99         0G    0.02954    0.01359   0.001396         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.978      0.995      0.872\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      31/99         0G    0.02833    0.01308   0.001376         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.978      0.995      0.872\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      32/99         0G    0.02833    0.01308   0.001376         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.974      0.995      0.738\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      33/99         0G    0.02957    0.01284   0.001348         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.974      0.995      0.738\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      34/99         0G    0.02957    0.01284   0.001348         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.971      0.995      0.894\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      35/99         0G    0.02777    0.01242   0.001348         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.971      0.995      0.894\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      36/99         0G    0.02777    0.01242   0.001348         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.965      0.995      0.794\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      37/99         0G    0.02945    0.01219   0.001331         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.965      0.995      0.794\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      38/99         0G    0.02945    0.01219   0.001331         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.989       0.75      0.945      0.841\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      39/99         0G    0.02747     0.0119   0.001345         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.989       0.75      0.945      0.841\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      40/99         0G    0.02747     0.0119   0.001345         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.989       0.75      0.945      0.764\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      41/99         0G     0.0288    0.01157   0.001346         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.989       0.75      0.945      0.764\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      42/99         0G     0.0288    0.01157   0.001346         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4       0.99       0.75      0.945      0.816\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      43/99         0G    0.02688    0.01139   0.001369         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4       0.99       0.75      0.945      0.816\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      44/99         0G    0.02688    0.01139   0.001369         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4       0.99       0.75      0.945       0.75\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      45/99         0G    0.02784    0.01105    0.00138         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4       0.99       0.75      0.945       0.75\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      46/99         0G    0.02784    0.01105    0.00138         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.965      0.995      0.831\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      47/99         0G    0.02643    0.01091   0.001409         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.965      0.995      0.831\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      48/99         0G    0.02643    0.01091   0.001409         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.968      0.995       0.76\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      49/99         0G    0.02714    0.01058   0.001429         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.968      0.995       0.76\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      50/99         0G    0.02714    0.01058   0.001429         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.974      0.995      0.831\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      51/99         0G    0.02419    0.01044   0.001461         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.974      0.995      0.831\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      52/99         0G    0.02419    0.01044   0.001461         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.974      0.995      0.831\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      53/99         0G    0.02419    0.01044   0.001461         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.975      0.995      0.779\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      54/99         0G    0.02594    0.01019   0.001483         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.975      0.995      0.779\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      55/99         0G    0.02594    0.01019   0.001483         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.975      0.995      0.779\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      56/99         0G    0.02594    0.01019   0.001483         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.977      0.995      0.837\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      57/99         0G    0.02415   0.009931   0.001513         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.977      0.995      0.837\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      58/99         0G    0.02415   0.009931   0.001513         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.977      0.995      0.837\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      59/99         0G    0.02415   0.009931   0.001513         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.973      0.995      0.717\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      60/99         0G    0.02665    0.00992   0.001539         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.973      0.995      0.717\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      61/99         0G    0.02665    0.00992   0.001539         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.973      0.995      0.717\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      62/99         0G    0.02665    0.00992   0.001539         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.976      0.995      0.829\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      63/99         0G    0.02191   0.009415   0.001572         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.976      0.995      0.829\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      64/99         0G    0.02191   0.009415   0.001572         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.976      0.995      0.829\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      65/99         0G    0.02191   0.009415   0.001572         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.971      0.995      0.761\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      66/99         0G    0.02257   0.009167     0.0016         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.971      0.995      0.761\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      67/99         0G    0.02257   0.009167     0.0016         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.971      0.995      0.761\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      68/99         0G    0.02257   0.009167     0.0016         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.977      0.995      0.837\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      69/99         0G    0.02285   0.009225   0.001615         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.977      0.995      0.837\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      70/99         0G    0.02285   0.009225   0.001615         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.977      0.995      0.837\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      71/99         0G    0.02285   0.009225   0.001615         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.975      0.995      0.773\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      72/99         0G    0.02319     0.0091   0.001632         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.975      0.995      0.773\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      73/99         0G    0.02319     0.0091   0.001632         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.975      0.995      0.773\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      74/99         0G    0.02319     0.0091   0.001632         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.976      0.995      0.836\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      75/99         0G    0.02066   0.008687   0.001644         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.976      0.995      0.836\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      76/99         0G    0.02066   0.008687   0.001644         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.976      0.995      0.836\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      77/99         0G    0.02066   0.008687   0.001644         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.974      0.995      0.773\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      78/99         0G    0.02185   0.008591   0.001664         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.974      0.995      0.773\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      79/99         0G    0.02185   0.008591   0.001664         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.974      0.995      0.773\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      80/99         0G    0.02185   0.008591   0.001664         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.975      0.995      0.836\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      81/99         0G    0.01897    0.00829   0.001669         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.975      0.995      0.836\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      82/99         0G    0.01897    0.00829   0.001669         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.975      0.995      0.836\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      83/99         0G    0.01897    0.00829   0.001669         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.973      0.995      0.778\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      84/99         0G    0.01991   0.008132   0.001671         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.973      0.995      0.778\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.973      0.995      0.778\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      87/99         0G    0.01991   0.008132   0.001671         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.975      0.995      0.836\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      88/99         0G    0.01833   0.007929   0.001667         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.975      0.995      0.836\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      89/99         0G    0.01833   0.007929   0.001667         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.975      0.995      0.836\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      90/99         0G    0.01833   0.007929   0.001667         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.975      0.995      0.836\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      91/99         0G    0.01833   0.007929   0.001667         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.973      0.995      0.773\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      85/99         0G    0.01991   0.008132   0.001671         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.973      0.995      0.778\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      86/99         0G    0.01991   0.008132   0.001671         90        640: 1\r\n",
      "      92/99         0G    0.01861   0.007746   0.001675         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.973      0.995      0.773\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      93/99         0G    0.01861   0.007746   0.001675         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.973      0.995      0.773\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      94/99         0G    0.01861   0.007746   0.001675         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.973      0.995      0.773\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      95/99         0G    0.01861   0.007746   0.001675         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.974      0.995       0.82\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      96/99         0G    0.01676   0.007456   0.001665         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.974      0.995       0.82\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      97/99         0G    0.01676   0.007456   0.001665         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.974      0.995       0.82\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      98/99         0G    0.01676   0.007456   0.001665         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.974      0.995       0.82\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      99/99         0G    0.01676   0.007456   0.001665         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.973      0.995      0.773\r\n",
      "\r\n",
      "100 epochs completed in 0.344 hours.\r\n",
      "Optimizer stripped from runs/train/exp23/weights/last.pt, 14.9MB\r\n",
      "Optimizer stripped from runs/train/exp23/weights/best.pt, 14.9MB\r\n",
      "\r\n",
      "Validating runs/train/exp23/weights/best.pt...\r\n",
      "Fusing layers... \r\n",
      "YOLOv5s summary: 157 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.981      0.995      0.894\r\n",
      "                   cat          4          4          1      0.981      0.995      0.894\r\n",
      "Results saved to \u001B[1mruns/train/exp23\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 640 --epochs 100 --data custom_dataset/custom_dataset.yaml  --weights 'yolov5s.pt' --cfg yolov5s.yaml --hyp hyp/hyp.scratch-low.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T09:27:18.118137Z",
     "start_time": "2024-06-21T09:02:04.558758Z"
    }
   },
   "id": "a53b2184ac24d1c0",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mweights=yolov5s.pt, cfg=yolov5s.yaml, data=custom_dataset/custom_dataset.yaml, hyp=hyp/hyp.scratch-low.yaml, epochs=250, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\r\n",
      "Command 'git fetch ultralytics' timed out after 5 seconds\r\n",
      "YOLOv5 üöÄ e8f8ccfe Python-3.11.5 torch-2.2.1 CPU\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mhyperparameters: \u001B[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0\r\n",
      "\u001B[34m\u001B[1mComet: \u001B[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\r\n",
      "ClearML Task: created new task id=e4a340f617344b4cb6cad0e852745eb4\r\n",
      "ClearML results page: https://app.clear.ml/projects/40862dec8602479f8c193e1bac487205/experiments/e4a340f617344b4cb6cad0e852745eb4/output/log\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "\r\n",
      "                 from  n    params  module                                  arguments                     \r\n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \r\n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \r\n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \r\n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \r\n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \r\n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \r\n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \r\n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \r\n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \r\n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \r\n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \r\n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \r\n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \r\n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \r\n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \r\n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \r\n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \r\n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \r\n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \r\n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \r\n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \r\n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \r\n",
      " 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\r\n",
      "YOLOv5s summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\r\n",
      "\r\n",
      "Transferred 348/349 items from yolov5s.pt\r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0), 60 bias\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov5/\u001B[0m\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mAutoAnchor: \u001B[0m3.94 anchors/target, 0.989 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\r\n",
      "Plotting labels to runs/train/exp24/labels.jpg... \r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 8 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/train/exp24\u001B[0m\r\n",
      "Starting training for 250 epochs...\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      0/249         0G    0.04622    0.03529    0.01086         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.979          1      0.995      0.874\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      1/249         0G    0.04553    0.03488    0.01059         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.992      0.995      0.842\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      2/249         0G    0.04475      0.034   0.009911         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.988      0.995      0.842\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      3/249         0G    0.04359    0.03264   0.008926         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.984      0.995      0.842\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      4/249         0G    0.04193    0.03094   0.007907         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.981      0.995      0.816\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      5/249         0G    0.03993     0.0291   0.006968         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.994          1      0.995      0.797\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      6/249         0G    0.03797    0.02726   0.006126         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.996          1      0.995      0.816\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      7/249         0G    0.03637    0.02553   0.005384         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.998          1      0.995      0.821\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      8/249         0G    0.03507    0.02391   0.004764         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.999          1      0.995      0.821\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      9/249         0G    0.03381    0.02248   0.004229         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.998      0.995      0.821\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     10/249         0G    0.03253    0.02125   0.003747         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.996      0.995      0.816\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     11/249         0G    0.03126     0.0202   0.003289         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.993      0.995      0.804\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     12/249         0G    0.03017    0.01929   0.002864         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.991      0.995      0.763\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     13/249         0G    0.02912    0.01851   0.002494         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.989      0.995       0.85\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     14/249         0G    0.02871    0.01782     0.0022         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.987      0.995      0.726\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     15/249         0G    0.02858    0.01719   0.001992         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.985      0.995       0.85\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     16/249         0G    0.02864    0.01664   0.001846         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.984      0.995      0.728\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     17/249         0G    0.02851      0.016   0.001738         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.984      0.995      0.728\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     18/249         0G    0.02851      0.016   0.001738         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.983      0.995      0.861\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     19/249         0G     0.0298    0.01561   0.001646         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.983      0.995      0.861\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     20/249         0G     0.0298    0.01561   0.001646         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.983      0.995       0.75\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     21/249         0G    0.02949    0.01492   0.001576         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.983      0.995       0.75\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     22/249         0G    0.02949    0.01492   0.001576         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1       0.98      0.995       0.86\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     23/249         0G    0.03242    0.01476   0.001504         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1       0.98      0.995       0.86\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     24/249         0G    0.03242    0.01476   0.001504         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.981      0.995      0.784\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     25/249         0G    0.02895    0.01391   0.001462         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.981      0.995      0.784\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     26/249         0G    0.02895    0.01391   0.001462         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.978      0.995       0.85\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     27/249         0G    0.03293    0.01403   0.001411         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.978      0.995       0.85\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     28/249         0G    0.03293    0.01403   0.001411         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.977      0.995      0.772\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     29/249         0G    0.02898    0.01309   0.001392         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.977      0.995      0.772\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     30/249         0G    0.02898    0.01309   0.001392         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.972      0.995       0.85\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     31/249         0G    0.03312    0.01328   0.001362         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.972      0.995       0.85\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     32/249         0G    0.03312    0.01328   0.001362         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.966      0.995      0.738\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     33/249         0G    0.02928    0.01255   0.001369         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.966      0.995      0.738\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     34/249         0G    0.02928    0.01255   0.001369         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.963      0.995       0.85\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     35/249         0G    0.03323    0.01268    0.00136         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.963      0.995       0.85\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     36/249         0G    0.03323    0.01268    0.00136         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4       0.99       0.75      0.945      0.723\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     37/249         0G    0.02967    0.01195   0.001386         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4       0.99       0.75      0.945      0.723\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     38/249         0G    0.02967    0.01195   0.001386         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.991       0.75      0.945      0.815\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     39/249         0G    0.03248    0.01195   0.001402         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.991       0.75      0.945      0.815\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     40/249         0G    0.03248    0.01195   0.001402         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.992       0.75      0.945      0.757\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     41/249         0G    0.03003    0.01165   0.001441         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.992       0.75      0.945      0.757\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     42/249         0G    0.03003    0.01165   0.001441         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.992       0.75      0.945      0.739\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     43/249         0G    0.03205    0.01171    0.00148         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.992       0.75      0.945      0.739\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     44/249         0G    0.03205    0.01171    0.00148         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.992       0.75      0.945      0.751\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     45/249         0G    0.02974    0.01086   0.001527         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.992       0.75      0.945      0.751\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     46/249         0G    0.02974    0.01086   0.001527         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.967      0.995      0.787\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     47/249         0G    0.03048    0.01086   0.001581         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.967      0.995      0.787\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     48/249         0G    0.03048    0.01086   0.001581         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.972      0.995      0.774\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     49/249         0G    0.02786     0.0107   0.001632         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.972      0.995      0.774\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     50/249         0G    0.02786     0.0107   0.001632         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.968      0.995      0.794\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     51/249         0G    0.03111    0.01071   0.001694         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.968      0.995      0.794\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     52/249         0G    0.03111    0.01071   0.001694         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.968      0.995      0.794\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     53/249         0G    0.03111    0.01071   0.001694         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.972      0.995      0.779\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     54/249         0G    0.02614    0.01018   0.001747         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.972      0.995      0.779\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "     55/249         0G    0.02614    0.01018   0.001747         90        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov5/train.py\", line 848, in <module>\r\n",
      "    main(opt)\r\n",
      "  File \"/Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov5/train.py\", line 623, in main\r\n",
      "    train(opt.hyp, opt, device, callbacks)\r\n",
      "  File \"/Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov5/train.py\", line 426, in train\r\n",
      "    results, maps, _ = validate.run(\r\n",
      "                       ^^^^^^^^^^^^^\r\n",
      "  File \"/Users/khumachbayramova/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n",
      "    return func(*args, **kwargs)\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov5/val.py\", line 224, in run\r\n",
      "    for batch_i, (im, targets, paths, shapes) in enumerate(pbar):\r\n",
      "  File \"/Users/khumachbayramova/anaconda3/lib/python3.11/site-packages/tqdm/std.py\", line 1178, in __iter__\r\n",
      "    for obj in iterable:\r\n",
      "  File \"/Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov5/utils/dataloaders.py\", line 239, in __iter__\r\n",
      "    yield next(self.iterator)\r\n",
      "          ^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/khumachbayramova/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 631, in __next__\r\n",
      "    data = self._next_data()\r\n",
      "           ^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/khumachbayramova/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1346, in _next_data\r\n",
      "    return self._process_data(data)\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/khumachbayramova/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1372, in _process_data\r\n",
      "    data.reraise()\r\n",
      "  File \"/Users/khumachbayramova/anaconda3/lib/python3.11/site-packages/torch/_utils.py\", line 722, in reraise\r\n",
      "    raise exception\r\n",
      "AssertionError: Caught AssertionError in DataLoader worker process 3.\r\n",
      "Original Traceback (most recent call last):\r\n",
      "  File \"/Users/khumachbayramova/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\r\n",
      "    data = fetcher.fetch(index)\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/khumachbayramova/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\r\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/khumachbayramova/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\r\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\r\n",
      "            ~~~~~~~~~~~~^^^^^\r\n",
      "  File \"/Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov5/utils/dataloaders.py\", line 781, in __getitem__\r\n",
      "    img, (h0, w0), (h, w) = self.load_image(index)\r\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov5/utils/dataloaders.py\", line 857, in load_image\r\n",
      "    assert im is not None, f\"Image Not Found {f}\"\r\n",
      "           ^^^^^^^^^^^^^^\r\n",
      "AssertionError: Image Not Found /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov5/custom_dataset/custom_dataset/images/test/000000565462.jpg\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 640 --epochs 250 --data custom_dataset/custom_dataset.yaml  --weights 'yolov5s.pt' --cfg yolov5s.yaml --hyp hyp/hyp.scratch-low.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T09:36:44.416729Z",
     "start_time": "2024-06-21T09:23:38.701180Z"
    }
   },
   "id": "468129eb64ca34a2",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!python train.py --img 640 --epochs 150 --data cats_dataset_short/cats_dataset_short.yaml  --weights '' --cfg yolov5s.yaml --hyp hyp/hyp.scratch-low.yaml"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12f9c2792934b9c9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mweights=yolov5s.pt, cfg=yolov5s.yaml, data=custom_dataset/custom_dataset.yaml, hyp=hyp/hyp.scratch-low.yaml, epochs=10, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\r\n",
      "\u001B[34m\u001B[1mgithub: \u001B[0m‚ö†Ô∏è YOLOv5 is out of date by 2814 commits. Use 'git pull ultralytics master' or 'git clone https://github.com/ultralytics/yolov5' to update.\r\n",
      "YOLOv5 üöÄ 0f3aa6b3 Python-3.11.5 torch-2.2.1 CPU\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mhyperparameters: \u001B[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0\r\n",
      "\u001B[34m\u001B[1mComet: \u001B[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\r\n",
      "ClearML Task: created new task id=4d96c7fa2be645e894f45eda895ecf3e\r\n",
      "ClearML results page: https://app.clear.ml/projects/40862dec8602479f8c193e1bac487205/experiments/4d96c7fa2be645e894f45eda895ecf3e/output/log\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "\r\n",
      "                 from  n    params  module                                  arguments                     \r\n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \r\n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \r\n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \r\n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \r\n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \r\n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \r\n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \r\n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \r\n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \r\n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \r\n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \r\n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \r\n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \r\n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \r\n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \r\n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \r\n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \r\n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \r\n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \r\n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \r\n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \r\n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \r\n",
      " 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\r\n",
      "YOLOv5s summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\r\n",
      "\r\n",
      "Transferred 348/349 items from yolov5s.pt\r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0), 60 bias\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov5/\u001B[0m\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mAutoAnchor: \u001B[0m3.94 anchors/target, 0.989 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\r\n",
      "Plotting labels to runs/train/exp38/labels.jpg... \r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 8 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/train/exp38\u001B[0m\r\n",
      "Starting training for 10 epochs...\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_lossgroup_lasso  Instances       Size\r\n",
      "        0/9         0G    0.04622    0.03529    0.01086          0         90   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.979          1      0.995      0.874\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_lossgroup_lasso  Instances       Size\r\n",
      "        1/9         0G    0.04553    0.03489    0.01059          0         90   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.993      0.995      0.842\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_lossgroup_lasso  Instances       Size\r\n",
      "        2/9         0G    0.04478    0.03408   0.009937          0         90   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.988      0.995      0.842\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_lossgroup_lasso  Instances       Size\r\n",
      "        3/9         0G    0.04375    0.03291   0.009039          0         90   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.985      0.995      0.842\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_lossgroup_lasso  Instances       Size\r\n",
      "        4/9         0G    0.04235    0.03152   0.008144          0         90   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.982      0.995      0.842\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_lossgroup_lasso  Instances       Size\r\n",
      "        5/9         0G    0.04076    0.03008   0.007369          0         90   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1       0.98      0.995      0.815\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_lossgroup_lasso  Instances       Size\r\n",
      "        6/9         0G    0.03925    0.02872   0.006688          0         90   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.996          1      0.995      0.797\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_lossgroup_lasso  Instances       Size\r\n",
      "        7/9         0G    0.03792    0.02751   0.006122          0         90   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.978      0.995      0.815\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_lossgroup_lasso  Instances       Size\r\n",
      "        8/9         0G    0.03687    0.02647   0.005658          0         90   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.998          1      0.995      0.815\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_lossgroup_lasso  Instances       Size\r\n",
      "        9/9         0G     0.0361     0.0256   0.005291          0         90   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1          1      0.995      0.815\r\n",
      "\r\n",
      "10 epochs completed in 0.034 hours.\r\n",
      "Optimizer stripped from runs/train/exp38/weights/last.pt, 14.9MB\r\n",
      "Optimizer stripped from runs/train/exp38/weights/best.pt, 14.9MB\r\n",
      "\r\n",
      "Validating runs/train/exp38/weights/best.pt...\r\n",
      "Fusing layers... \r\n",
      "YOLOv5s summary: 157 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.979          1      0.995      0.874\r\n",
      "                   cat          4          4      0.979          1      0.995      0.874\r\n",
      "Results saved to \u001B[1mruns/train/exp38\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 640 --epochs 10 --data custom_dataset/custom_dataset.yaml  --weights 'yolov5s.pt' --cfg yolov5s.yaml --hyp hyp/hyp.scratch-low.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T15:57:10.974853Z",
     "start_time": "2024-06-21T15:54:10.656762Z"
    }
   },
   "id": "a954b4623674b59a",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mweights=yolov5s.pt, cfg=yolov5s.yaml, data=custom_dataset/custom_dataset.yaml, hyp=hyp/hyp.scratch-low.yaml, epochs=3, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\r\n",
      "\u001B[34m\u001B[1mgithub: \u001B[0m‚ö†Ô∏è YOLOv5 is out of date by 2814 commits. Use 'git pull ultralytics master' or 'git clone https://github.com/ultralytics/yolov5' to update.\r\n",
      "YOLOv5 üöÄ 0f3aa6b3 Python-3.11.5 torch-2.2.1 CPU\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mhyperparameters: \u001B[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0\r\n",
      "\u001B[34m\u001B[1mComet: \u001B[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\r\n",
      "ClearML Task: created new task id=4ecdd0160b864a9a8edd6e2df7043469\r\n",
      "ClearML results page: https://app.clear.ml/projects/40862dec8602479f8c193e1bac487205/experiments/4ecdd0160b864a9a8edd6e2df7043469/output/log\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "\r\n",
      "                 from  n    params  module                                  arguments                     \r\n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \r\n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \r\n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \r\n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \r\n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \r\n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \r\n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \r\n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \r\n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \r\n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \r\n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \r\n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \r\n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \r\n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \r\n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \r\n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \r\n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \r\n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \r\n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \r\n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \r\n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \r\n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \r\n",
      " 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\r\n",
      "YOLOv5s summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\r\n",
      "\r\n",
      "Transferred 348/349 items from yolov5s.pt\r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0), 60 bias\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov5/\u001B[0m\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mAutoAnchor: \u001B[0m3.94 anchors/target, 0.989 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\r\n",
      "Plotting labels to runs/train/exp45/labels.jpg... \r\n",
      "MODEL DetectionModel(\r\n",
      "  (model): Sequential(\r\n",
      "    (0): Conv(\r\n",
      "      (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2), bias=False)\r\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (1): Conv(\r\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (2): C3(\r\n",
      "      (cv1): Conv(\r\n",
      "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (cv2): Conv(\r\n",
      "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (cv3): Conv(\r\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (m): Sequential(\r\n",
      "        (0): Bottleneck(\r\n",
      "          (cv1): Conv(\r\n",
      "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (cv2): Conv(\r\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (3): Conv(\r\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (4): C3(\r\n",
      "      (cv1): Conv(\r\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (cv2): Conv(\r\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (cv3): Conv(\r\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (m): Sequential(\r\n",
      "        (0): Bottleneck(\r\n",
      "          (cv1): Conv(\r\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (cv2): Conv(\r\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (1): Bottleneck(\r\n",
      "          (cv1): Conv(\r\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (cv2): Conv(\r\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (5): Conv(\r\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (6): C3(\r\n",
      "      (cv1): Conv(\r\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (cv2): Conv(\r\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (cv3): Conv(\r\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (m): Sequential(\r\n",
      "        (0): Bottleneck(\r\n",
      "          (cv1): Conv(\r\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (cv2): Conv(\r\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (1): Bottleneck(\r\n",
      "          (cv1): Conv(\r\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (cv2): Conv(\r\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (2): Bottleneck(\r\n",
      "          (cv1): Conv(\r\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (cv2): Conv(\r\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (7): Conv(\r\n",
      "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (8): C3(\r\n",
      "      (cv1): Conv(\r\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (cv2): Conv(\r\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (cv3): Conv(\r\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (m): Sequential(\r\n",
      "        (0): Bottleneck(\r\n",
      "          (cv1): Conv(\r\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (cv2): Conv(\r\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (9): SPPF(\r\n",
      "      (cv1): Conv(\r\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (cv2): Conv(\r\n",
      "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\r\n",
      "    )\r\n",
      "    (10): Conv(\r\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (11): Upsample(scale_factor=2.0, mode='nearest')\r\n",
      "    (12): Concat()\r\n",
      "    (13): C3(\r\n",
      "      (cv1): Conv(\r\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (cv2): Conv(\r\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (cv3): Conv(\r\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (m): Sequential(\r\n",
      "        (0): Bottleneck(\r\n",
      "          (cv1): Conv(\r\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (cv2): Conv(\r\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (14): Conv(\r\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (15): Upsample(scale_factor=2.0, mode='nearest')\r\n",
      "    (16): Concat()\r\n",
      "    (17): C3(\r\n",
      "      (cv1): Conv(\r\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (cv2): Conv(\r\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (cv3): Conv(\r\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (m): Sequential(\r\n",
      "        (0): Bottleneck(\r\n",
      "          (cv1): Conv(\r\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (cv2): Conv(\r\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (18): Conv(\r\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (19): Concat()\r\n",
      "    (20): C3(\r\n",
      "      (cv1): Conv(\r\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (cv2): Conv(\r\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (cv3): Conv(\r\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (m): Sequential(\r\n",
      "        (0): Bottleneck(\r\n",
      "          (cv1): Conv(\r\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (cv2): Conv(\r\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (21): Conv(\r\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (22): Concat()\r\n",
      "    (23): C3(\r\n",
      "      (cv1): Conv(\r\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (cv2): Conv(\r\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (cv3): Conv(\r\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "        (act): SiLU(inplace=True)\r\n",
      "      )\r\n",
      "      (m): Sequential(\r\n",
      "        (0): Bottleneck(\r\n",
      "          (cv1): Conv(\r\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "          (cv2): Conv(\r\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "            (act): SiLU(inplace=True)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (24): Detect(\r\n",
      "      (m): ModuleList(\r\n",
      "        (0): Conv2d(128, 255, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "        (1): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "        (2): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "      )\r\n",
      "    )\r\n",
      "  )\r\n",
      ")\r\n",
      "MODEL.MODEL Sequential(\r\n",
      "  (0): Conv(\r\n",
      "    (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2), bias=False)\r\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "    (act): SiLU(inplace=True)\r\n",
      "  )\r\n",
      "  (1): Conv(\r\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "    (act): SiLU(inplace=True)\r\n",
      "  )\r\n",
      "  (2): C3(\r\n",
      "    (cv1): Conv(\r\n",
      "      (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (cv2): Conv(\r\n",
      "      (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (cv3): Conv(\r\n",
      "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (m): Sequential(\r\n",
      "      (0): Bottleneck(\r\n",
      "        (cv1): Conv(\r\n",
      "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "        (cv2): Conv(\r\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "  )\r\n",
      "  (3): Conv(\r\n",
      "    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "    (act): SiLU(inplace=True)\r\n",
      "  )\r\n",
      "  (4): C3(\r\n",
      "    (cv1): Conv(\r\n",
      "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (cv2): Conv(\r\n",
      "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (cv3): Conv(\r\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (m): Sequential(\r\n",
      "      (0): Bottleneck(\r\n",
      "        (cv1): Conv(\r\n",
      "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "        (cv2): Conv(\r\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (1): Bottleneck(\r\n",
      "        (cv1): Conv(\r\n",
      "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "        (cv2): Conv(\r\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "  )\r\n",
      "  (5): Conv(\r\n",
      "    (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "    (act): SiLU(inplace=True)\r\n",
      "  )\r\n",
      "  (6): C3(\r\n",
      "    (cv1): Conv(\r\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (cv2): Conv(\r\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (cv3): Conv(\r\n",
      "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (m): Sequential(\r\n",
      "      (0): Bottleneck(\r\n",
      "        (cv1): Conv(\r\n",
      "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "        (cv2): Conv(\r\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (1): Bottleneck(\r\n",
      "        (cv1): Conv(\r\n",
      "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "        (cv2): Conv(\r\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (2): Bottleneck(\r\n",
      "        (cv1): Conv(\r\n",
      "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "        (cv2): Conv(\r\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "  )\r\n",
      "  (7): Conv(\r\n",
      "    (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "    (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "    (act): SiLU(inplace=True)\r\n",
      "  )\r\n",
      "  (8): C3(\r\n",
      "    (cv1): Conv(\r\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (cv2): Conv(\r\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (cv3): Conv(\r\n",
      "      (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (m): Sequential(\r\n",
      "      (0): Bottleneck(\r\n",
      "        (cv1): Conv(\r\n",
      "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "        (cv2): Conv(\r\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "  )\r\n",
      "  (9): SPPF(\r\n",
      "    (cv1): Conv(\r\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (cv2): Conv(\r\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\r\n",
      "  )\r\n",
      "  (10): Conv(\r\n",
      "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "    (act): SiLU(inplace=True)\r\n",
      "  )\r\n",
      "  (11): Upsample(scale_factor=2.0, mode='nearest')\r\n",
      "  (12): Concat()\r\n",
      "  (13): C3(\r\n",
      "    (cv1): Conv(\r\n",
      "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (cv2): Conv(\r\n",
      "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (cv3): Conv(\r\n",
      "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (m): Sequential(\r\n",
      "      (0): Bottleneck(\r\n",
      "        (cv1): Conv(\r\n",
      "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "        (cv2): Conv(\r\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "  )\r\n",
      "  (14): Conv(\r\n",
      "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "    (act): SiLU(inplace=True)\r\n",
      "  )\r\n",
      "  (15): Upsample(scale_factor=2.0, mode='nearest')\r\n",
      "  (16): Concat()\r\n",
      "  (17): C3(\r\n",
      "    (cv1): Conv(\r\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (cv2): Conv(\r\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (cv3): Conv(\r\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (m): Sequential(\r\n",
      "      (0): Bottleneck(\r\n",
      "        (cv1): Conv(\r\n",
      "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "        (cv2): Conv(\r\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "  )\r\n",
      "  (18): Conv(\r\n",
      "    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "    (act): SiLU(inplace=True)\r\n",
      "  )\r\n",
      "  (19): Concat()\r\n",
      "  (20): C3(\r\n",
      "    (cv1): Conv(\r\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (cv2): Conv(\r\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (cv3): Conv(\r\n",
      "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (m): Sequential(\r\n",
      "      (0): Bottleneck(\r\n",
      "        (cv1): Conv(\r\n",
      "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "        (cv2): Conv(\r\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "  )\r\n",
      "  (21): Conv(\r\n",
      "    (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\r\n",
      "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "    (act): SiLU(inplace=True)\r\n",
      "  )\r\n",
      "  (22): Concat()\r\n",
      "  (23): C3(\r\n",
      "    (cv1): Conv(\r\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (cv2): Conv(\r\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (cv3): Conv(\r\n",
      "      (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "      (act): SiLU(inplace=True)\r\n",
      "    )\r\n",
      "    (m): Sequential(\r\n",
      "      (0): Bottleneck(\r\n",
      "        (cv1): Conv(\r\n",
      "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "        (cv2): Conv(\r\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\r\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\r\n",
      "          (act): SiLU(inplace=True)\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "  )\r\n",
      "  (24): Detect(\r\n",
      "    (m): ModuleList(\r\n",
      "      (0): Conv2d(128, 255, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "      (1): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "      (2): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\r\n",
      "    )\r\n",
      "  )\r\n",
      ")\r\n",
      "–°–ö–û–õ–¨–ö–û –ì–†–£–ü–ü–ê 0\r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 8 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/train/exp45\u001B[0m\r\n",
      "Starting training for 3 epochs...\r\n",
      "\r\n",
      "        Epoch      GPU_mem     box_loss     obj_loss     cls_loss  group_lasso    Instances         Size\r\n",
      "          0/2           0G    0.04622    0.03529    0.01086          0         9\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.979          1      0.995      0.874\r\n",
      "\r\n",
      "        Epoch      GPU_mem     box_loss     obj_loss     cls_loss  group_lasso    Instances         Size\r\n",
      "          1/2           0G    0.04553    0.03489    0.01059          0         9\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.993      0.995      0.842\r\n",
      "\r\n",
      "        Epoch      GPU_mem     box_loss     obj_loss     cls_loss  group_lasso    Instances         Size\r\n",
      "          2/2           0G    0.04485    0.03415   0.009999          0         9\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.989      0.995      0.841\r\n",
      "\r\n",
      "3 epochs completed in 0.015 hours.\r\n",
      "Optimizer stripped from runs/train/exp45/weights/last.pt, 14.9MB\r\n",
      "Optimizer stripped from runs/train/exp45/weights/best.pt, 14.9MB\r\n",
      "\r\n",
      "Validating runs/train/exp45/weights/best.pt...\r\n",
      "Fusing layers... \r\n",
      "YOLOv5s summary: 157 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.979          1      0.995      0.874\r\n",
      "                   cat          4          4      0.979          1      0.995      0.874\r\n",
      "Results saved to \u001B[1mruns/train/exp45\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 640 --epochs 3 --data custom_dataset/custom_dataset.yaml  --weights 'yolov5s.pt' --cfg yolov5s.yaml --hyp hyp/hyp.scratch-low.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T09:42:32.185804Z",
     "start_time": "2024-06-22T09:40:52.483463Z"
    }
   },
   "id": "b98e26b20757a195",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mweights=yolov5s.pt, cfg=yolov5s.yaml, data=custom_dataset/custom_dataset.yaml, hyp=hyp/hyp.scratch-low.yaml, epochs=2, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\r\n",
      "\u001B[34m\u001B[1mgithub: \u001B[0m‚ö†Ô∏è YOLOv5 is out of date by 2814 commits. Use 'git pull ultralytics master' or 'git clone https://github.com/ultralytics/yolov5' to update.\r\n",
      "YOLOv5 üöÄ 0f3aa6b3 Python-3.11.5 torch-2.2.1 CPU\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mhyperparameters: \u001B[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0\r\n",
      "\u001B[34m\u001B[1mComet: \u001B[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\r\n",
      "ClearML Task: created new task id=d47b4534cce746828a0d95d89061dde5\r\n",
      "ClearML results page: https://app.clear.ml/projects/40862dec8602479f8c193e1bac487205/experiments/d47b4534cce746828a0d95d89061dde5/output/log\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "\r\n",
      "                 from  n    params  module                                  arguments                     \r\n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \r\n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \r\n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \r\n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \r\n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \r\n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \r\n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \r\n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \r\n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \r\n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \r\n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \r\n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \r\n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \r\n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \r\n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \r\n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \r\n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \r\n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \r\n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \r\n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \r\n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \r\n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \r\n",
      " 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\r\n",
      "YOLOv5s summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\r\n",
      "\r\n",
      "Transferred 348/349 items from yolov5s.pt\r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0), 60 bias\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov5/\u001B[0m\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mAutoAnchor: \u001B[0m3.94 anchors/target, 0.989 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\r\n",
      "Plotting labels to runs/train/exp52/labels.jpg... \r\n",
      "–°–ö–û–õ–¨–ö–û –ì–†–£–ü–ü–ê 6\r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 8 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/train/exp52\u001B[0m\r\n",
      "Starting training for 2 epochs...\r\n",
      "\r\n",
      "        Epoch      GPU_mem     box_loss     obj_loss     cls_loss  group_lasso    Instances         Size\r\n",
      "          0/1           0G      0.04622      0.03529      0.01086        345.2  \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.979          1      0.995      0.874\r\n",
      "\r\n",
      "        Epoch      GPU_mem     box_loss     obj_loss     cls_loss  group_lasso    Instances         Size\r\n",
      "          1/1           0G      0.04615      0.03525      0.01084        345.2  \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.998      0.995      0.815\r\n",
      "\r\n",
      "2 epochs completed in 0.009 hours.\r\n",
      "Optimizer stripped from runs/train/exp52/weights/last.pt, 14.9MB\r\n",
      "Optimizer stripped from runs/train/exp52/weights/best.pt, 14.9MB\r\n",
      "\r\n",
      "Validating runs/train/exp52/weights/best.pt...\r\n",
      "Fusing layers... \r\n",
      "YOLOv5s summary: 157 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.979          1      0.995      0.874\r\n",
      "                   cat          4          4      0.979          1      0.995      0.874\r\n",
      "Results saved to \u001B[1mruns/train/exp52\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 640 --epochs 2 --data custom_dataset/custom_dataset.yaml  --weights 'yolov5s.pt' --cfg yolov5s.yaml --hyp hyp/hyp.scratch-low.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T10:02:49.540960Z",
     "start_time": "2024-06-22T10:01:30.684944Z"
    }
   },
   "id": "bf589fcb1cedf21e",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mweights=yolov5s.pt, cfg=yolov5s.yaml, data=custom_dataset/custom_dataset.yaml, hyp=hyp/hyp.scratch-low.yaml, epochs=10, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\r\n",
      "\u001B[34m\u001B[1mgithub: \u001B[0m‚ö†Ô∏è YOLOv5 is out of date by 2814 commits. Use 'git pull ultralytics master' or 'git clone https://github.com/ultralytics/yolov5' to update.\r\n",
      "YOLOv5 üöÄ 0f3aa6b3 Python-3.11.5 torch-2.2.1 CPU\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mhyperparameters: \u001B[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0\r\n",
      "\u001B[34m\u001B[1mComet: \u001B[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\r\n",
      "ClearML Task: created new task id=b9691d92bd1e40dba75d7db7cdbe4d07\r\n",
      "ClearML results page: https://app.clear.ml/projects/40862dec8602479f8c193e1bac487205/experiments/b9691d92bd1e40dba75d7db7cdbe4d07/output/log\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "\r\n",
      "                 from  n    params  module                                  arguments                     \r\n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \r\n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \r\n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \r\n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \r\n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \r\n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \r\n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \r\n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \r\n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \r\n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \r\n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \r\n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \r\n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \r\n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \r\n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \r\n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \r\n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \r\n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \r\n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \r\n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \r\n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \r\n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \r\n",
      " 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\r\n",
      "YOLOv5s summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\r\n",
      "\r\n",
      "Transferred 348/349 items from yolov5s.pt\r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0), 60 bias\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov5/\u001B[0m\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mAutoAnchor: \u001B[0m3.94 anchors/target, 0.989 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\r\n",
      "Plotting labels to runs/train/exp53/labels.jpg... \r\n",
      "–°–ö–û–õ–¨–ö–û –ì–†–£–ü–ü–ê 6\r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 8 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/train/exp53\u001B[0m\r\n",
      "Starting training for 10 epochs...\r\n",
      "\r\n",
      "        Epoch      GPU_mem     box_loss     obj_loss     cls_loss  group_lasso    Instances         Size\r\n",
      "          0/9           0G      0.04622      0.03529      0.01086        345.2  \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.979          1      0.995      0.874\r\n",
      "\r\n",
      "        Epoch      GPU_mem     box_loss     obj_loss     cls_loss  group_lasso    Instances         Size\r\n",
      "          1/9           0G      0.04615      0.03525      0.01084        345.2  \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.998      0.995      0.815\r\n",
      "\r\n",
      "        Epoch      GPU_mem     box_loss     obj_loss     cls_loss  group_lasso    Instances         Size\r\n",
      "          2/9           0G      0.04602      0.03524      0.01078        345.2  \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.994      0.995      0.815\r\n",
      "\r\n",
      "        Epoch      GPU_mem     box_loss     obj_loss     cls_loss  group_lasso    Instances         Size\r\n",
      "          3/9           0G      0.04583      0.03517      0.01068        345.2  \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.992      0.995       0.84\r\n",
      "\r\n",
      "        Epoch      GPU_mem     box_loss     obj_loss     cls_loss  group_lasso    Instances         Size\r\n",
      "          4/9           0G      0.04561      0.03505      0.01054        345.1  \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1       0.99      0.995       0.84\r\n",
      "\r\n",
      "        Epoch      GPU_mem     box_loss     obj_loss     cls_loss  group_lasso    Instances         Size\r\n",
      "          5/9           0G      0.04537       0.0349      0.01037          345  \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.988      0.995       0.84\r\n",
      "\r\n",
      "        Epoch      GPU_mem     box_loss     obj_loss     cls_loss  group_lasso    Instances         Size\r\n",
      "          6/9           0G      0.04512      0.03473      0.01019          345  \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.986      0.995       0.84\r\n",
      "\r\n",
      "        Epoch      GPU_mem     box_loss     obj_loss     cls_loss  group_lasso    Instances         Size\r\n",
      "          7/9           0G      0.04486      0.03453     0.009991        344.9  \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.985      0.995       0.84\r\n",
      "\r\n",
      "        Epoch      GPU_mem     box_loss     obj_loss     cls_loss  group_lasso    Instances         Size\r\n",
      "          8/9           0G      0.04461      0.03434       0.0098        344.8  \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.984      0.995       0.84\r\n",
      "\r\n",
      "        Epoch      GPU_mem     box_loss     obj_loss     cls_loss  group_lasso    Instances         Size\r\n",
      "          9/9           0G      0.04438      0.03415     0.009622        344.7  \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.983      0.995       0.84\r\n",
      "\r\n",
      "10 epochs completed in 0.039 hours.\r\n",
      "Optimizer stripped from runs/train/exp53/weights/last.pt, 14.9MB\r\n",
      "Optimizer stripped from runs/train/exp53/weights/best.pt, 14.9MB\r\n",
      "\r\n",
      "Validating runs/train/exp53/weights/best.pt...\r\n",
      "Fusing layers... \r\n",
      "YOLOv5s summary: 157 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.979          1      0.995      0.874\r\n",
      "                   cat          4          4      0.979          1      0.995      0.874\r\n",
      "Results saved to \u001B[1mruns/train/exp53\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 640 --epochs 10 --data custom_dataset/custom_dataset.yaml  --weights 'yolov5s.pt' --cfg yolov5s.yaml --hyp hyp/hyp.scratch-low.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T10:06:54.178646Z",
     "start_time": "2024-06-22T10:03:48.962488Z"
    }
   },
   "id": "4e48a386f5d3ad1c",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mweights=yolov5s.pt, cfg=yolov5s.yaml, data=custom_dataset/custom_dataset.yaml, hyp=hyp/hyp.scratch-low.yaml, epochs=2, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\r\n",
      "\u001B[34m\u001B[1mgithub: \u001B[0m‚ö†Ô∏è YOLOv5 is out of date by 2814 commits. Use 'git pull ultralytics master' or 'git clone https://github.com/ultralytics/yolov5' to update.\r\n",
      "YOLOv5 üöÄ 0f3aa6b3 Python-3.11.5 torch-2.2.1 CPU\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mhyperparameters: \u001B[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0\r\n",
      "\u001B[34m\u001B[1mComet: \u001B[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\r\n",
      "ClearML Task: created new task id=1706ae02dd26419dbeccee465576cf72\r\n",
      "ClearML results page: https://app.clear.ml/projects/40862dec8602479f8c193e1bac487205/experiments/1706ae02dd26419dbeccee465576cf72/output/log\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "\r\n",
      "                 from  n    params  module                                  arguments                     \r\n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \r\n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \r\n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \r\n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \r\n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \r\n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \r\n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \r\n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \r\n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \r\n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \r\n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \r\n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \r\n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \r\n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \r\n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \r\n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \r\n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \r\n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \r\n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \r\n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \r\n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \r\n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \r\n",
      " 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\r\n",
      "YOLOv5s summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\r\n",
      "\r\n",
      "Transferred 348/349 items from yolov5s.pt\r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0), 60 bias\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov5/\u001B[0m\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mAutoAnchor: \u001B[0m3.94 anchors/target, 0.989 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\r\n",
      "Plotting labels to runs/train/exp55/labels.jpg... \r\n",
      "–°–ö–û–õ–¨–ö–û –ì–†–£–ü–ü–ê 6\r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 8 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/train/exp55\u001B[0m\r\n",
      "Starting training for 2 epochs...\r\n",
      "\r\n",
      "        Epoch      GPU_mem     box_loss     obj_loss     cls_loss  group_lasso    Instances         Size\r\n",
      "          0/1           0G      0.04622      0.03529      0.01086        345.2  \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.979          1      0.995      0.874\r\n",
      "\r\n",
      "        Epoch      GPU_mem     box_loss     obj_loss     cls_loss  group_lasso    Instances         Size\r\n",
      "          1/1           0G      0.04615      0.03525      0.01084        345.2  \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.998      0.995      0.815\r\n",
      "\r\n",
      "2 epochs completed in 0.010 hours.\r\n",
      "Optimizer stripped from runs/train/exp55/weights/last.pt, 14.9MB\r\n",
      "Optimizer stripped from runs/train/exp55/weights/best.pt, 14.9MB\r\n",
      "\r\n",
      "Validating runs/train/exp55/weights/best.pt...\r\n",
      "Fusing layers... \r\n",
      "YOLOv5s summary: 157 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.979          1      0.995      0.874\r\n",
      "                   cat          4          4      0.979          1      0.995      0.874\r\n",
      "Results saved to \u001B[1mruns/train/exp55\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 640 --epochs 2 --data custom_dataset/custom_dataset.yaml  --weights 'yolov5s.pt' --cfg yolov5s.yaml --hyp hyp/hyp.scratch-low.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T10:31:36.308486Z",
     "start_time": "2024-06-22T10:30:15.429607Z"
    }
   },
   "id": "bfc9df0f4ed184dd",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov5/train.py\", line 83, in <module>\r\n",
      "    from utils.loss import ComputeLoss\r\n",
      "  File \"/Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov5/utils/loss.py\", line 207\r\n",
      "    def build_targets(self, p, targets):\r\n",
      "                                        ^\r\n",
      "IndentationError: unindent does not match any outer indentation level\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 640 --epochs 2 --data custom_dataset/custom_dataset.yaml  --weights 'yolov5s.pt' --cfg yolov5s.yaml --hyp hyp/hyp.scratch-low.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T13:19:36.001633Z",
     "start_time": "2024-06-23T13:19:28.722407Z"
    }
   },
   "id": "a2a60f317635bf85",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mweights=yolov5s.pt, cfg=yolov5s.yaml, data=custom_dataset/custom_dataset.yaml, hyp=hyp/hyp.scratch-low.yaml, epochs=10, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\r\n",
      "\u001B[34m\u001B[1mgithub: \u001B[0m‚ö†Ô∏è YOLOv5 is out of date by 2815 commits. Use 'git pull ultralytics master' or 'git clone https://github.com/ultralytics/yolov5' to update.\r\n",
      "YOLOv5 üöÄ 2e902ea4 Python-3.11.5 torch-2.2.1 CPU\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mhyperparameters: \u001B[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0\r\n",
      "\u001B[34m\u001B[1mComet: \u001B[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\r\n",
      "ClearML Task: created new task id=c3f66bf4d0f0452c9081bdf4bdbee52e\r\n",
      "ClearML results page: https://app.clear.ml/projects/40862dec8602479f8c193e1bac487205/experiments/c3f66bf4d0f0452c9081bdf4bdbee52e/output/log\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "\r\n",
      "                 from  n    params  module                                  arguments                     \r\n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \r\n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \r\n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \r\n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \r\n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \r\n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \r\n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \r\n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \r\n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \r\n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \r\n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \r\n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \r\n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \r\n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \r\n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \r\n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \r\n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \r\n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \r\n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \r\n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \r\n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \r\n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \r\n",
      " 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\r\n",
      "YOLOv5s summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\r\n",
      "\r\n",
      "Transferred 348/349 items from yolov5s.pt\r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0), 60 bias\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov5/\u001B[0m\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mAutoAnchor: \u001B[0m3.94 anchors/target, 0.989 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\r\n",
      "Plotting labels to runs/train/exp63/labels.jpg... \r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 8 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/train/exp63\u001B[0m\r\n",
      "Starting training for 10 epochs...\r\n",
      "\r\n",
      "            Epoch          GPU_mem         box_loss         obj_loss         cls_loss  rademacher_loss        Instances             Size\r\n",
      "              0/9               0G          0.04622          0.03529          0.\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.979          1      0.995      0.874\r\n",
      "\r\n",
      "            Epoch          GPU_mem         box_loss         obj_loss         cls_loss  rademacher_loss        Instances             Size\r\n",
      "              1/9               0G           0.0459          0.03513          0.\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.995      0.995      0.842\r\n",
      "\r\n",
      "            Epoch          GPU_mem         box_loss         obj_loss         cls_loss  rademacher_loss        Instances             Size\r\n",
      "              2/9               0G          0.04544          0.03485          0.\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.992      0.995      0.841\r\n",
      "\r\n",
      "            Epoch          GPU_mem         box_loss         obj_loss         cls_loss  rademacher_loss        Instances             Size\r\n",
      "              3/9               0G           0.0449          0.03437          0.\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.988      0.995      0.841\r\n",
      "\r\n",
      "            Epoch          GPU_mem         box_loss         obj_loss         cls_loss  rademacher_loss        Instances             Size\r\n",
      "              4/9               0G          0.04427          0.03375         0.0\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.986      0.995      0.841\r\n",
      "\r\n",
      "            Epoch          GPU_mem         box_loss         obj_loss         cls_loss  rademacher_loss        Instances             Size\r\n",
      "              5/9               0G          0.04356          0.03303         0.0\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.984      0.995      0.841\r\n",
      "\r\n",
      "            Epoch          GPU_mem         box_loss         obj_loss         cls_loss  rademacher_loss        Instances             Size\r\n",
      "              6/9               0G          0.04277          0.03227         0.0\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.982      0.995      0.841\r\n",
      "\r\n",
      "            Epoch          GPU_mem         box_loss         obj_loss         cls_loss  rademacher_loss        Instances             Size\r\n",
      "              7/9               0G          0.04194           0.0315         0.0\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.981      0.995      0.841\r\n",
      "\r\n",
      "            Epoch          GPU_mem         box_loss         obj_loss         cls_loss  rademacher_loss        Instances             Size\r\n",
      "              8/9               0G           0.0411           0.0308         0.0\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.979      0.995      0.841\r\n",
      "\r\n",
      "            Epoch          GPU_mem         box_loss         obj_loss         cls_loss  rademacher_loss        Instances             Size\r\n",
      "              9/9               0G          0.04035          0.03017         0.0\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.979      0.995      0.815\r\n",
      "\r\n",
      "10 epochs completed in 0.035 hours.\r\n",
      "Optimizer stripped from runs/train/exp63/weights/last.pt, 14.9MB\r\n",
      "Optimizer stripped from runs/train/exp63/weights/best.pt, 14.9MB\r\n",
      "\r\n",
      "Validating runs/train/exp63/weights/best.pt...\r\n",
      "Fusing layers... \r\n",
      "YOLOv5s summary: 157 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.979          1      0.995      0.874\r\n",
      "                   cat          4          4      0.979          1      0.995      0.874\r\n",
      "Results saved to \u001B[1mruns/train/exp63\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 640 --epochs 10 --data custom_dataset/custom_dataset.yaml  --weights 'yolov5s.pt' --cfg yolov5s.yaml --hyp hyp/hyp.scratch-low.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T11:29:55.998846Z",
     "start_time": "2024-06-23T11:27:04.739433Z"
    }
   },
   "id": "5e7d6e6c3abf5b53",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mdata=custom_dataset/custom_dataset.yaml, weights=['runs/train/exp63/weights/last.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\r\n",
      "YOLOv5 üöÄ 2e902ea4 Python-3.11.5 torch-2.2.1 CPU\r\n",
      "\r\n",
      "Fusing layers... \r\n",
      "YOLOv5s summary: 157 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov5/\u001B[0m\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.979      0.995      0.815\r\n",
      "Speed: 1.1ms pre-process, 90.0ms inference, 2.0ms NMS per image at shape (32, 3, 640, 640)\r\n",
      "Results saved to \u001B[1mruns/val/exp\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python val.py --weights runs/train/exp63/weights/last.pt --data custom_dataset/custom_dataset.yaml "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T11:30:51.562538Z",
     "start_time": "2024-06-23T11:30:27.413865Z"
    }
   },
   "id": "9713d4e92fd0bf85",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!python train.py --img 640 --epochs 50 --data custom_dataset/custom_dataset.yaml  --weights 'yolov5s.pt' --cfg yolov5s.yaml --hyp hyp/hyp.scratch-low.yaml"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf0ae8007db2cef4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!python val.py --weights runs/train/exp4/weights/last.pt --data custom_dataset/custom_dataset.yaml "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2011d5e279a0702"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mweights=yolov5s.pt, cfg=yolov5s.yaml, data=custom_dataset/custom_dataset.yaml, hyp=hyp/hyp.scratch-low.yaml, epochs=2, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\r\n",
      "\u001B[34m\u001B[1mgithub: \u001B[0m‚ö†Ô∏è YOLOv5 is out of date by 2815 commits. Use 'git pull ultralytics master' or 'git clone https://github.com/ultralytics/yolov5' to update.\r\n",
      "YOLOv5 üöÄ bc8669f8 Python-3.11.5 torch-2.2.1 CPU\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mhyperparameters: \u001B[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0\r\n",
      "\u001B[34m\u001B[1mComet: \u001B[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\r\n",
      "ClearML Task: created new task id=1608d18233e748aba828c849b97f7042\r\n",
      "ClearML results page: https://app.clear.ml/projects/40862dec8602479f8c193e1bac487205/experiments/1608d18233e748aba828c849b97f7042/output/log\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "\r\n",
      "                 from  n    params  module                                  arguments                     \r\n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \r\n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \r\n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \r\n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \r\n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \r\n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \r\n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \r\n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \r\n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \r\n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \r\n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \r\n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \r\n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \r\n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \r\n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \r\n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \r\n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \r\n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \r\n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \r\n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \r\n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \r\n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \r\n",
      " 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\r\n",
      "YOLOv5s summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\r\n",
      "\r\n",
      "Transferred 348/349 items from yolov5s.pt\r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0), 60 bias\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ù–ò–†/YOLO/yolov5/\u001B[0m\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mAutoAnchor: \u001B[0m3.94 anchors/target, 0.989 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\r\n",
      "Plotting labels to runs/train/exp66/labels.jpg... \r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 8 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/train/exp66\u001B[0m\r\n",
      "Starting training for 2 epochs...\r\n",
      "\r\n",
      "            Epoch          GPU_mem         box_loss         obj_loss         cls_loss  rademacher_loss      group_lasso        Instances             Size\r\n",
      "              0/1               0G          0.04622          0.03529          0.\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.979          1      0.995      0.874\r\n",
      "\r\n",
      "            Epoch          GPU_mem         box_loss         obj_loss         cls_loss  rademacher_loss      group_lasso        Instances             Size\r\n",
      "              1/1               0G          0.04615          0.03525          0.\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4          1      0.998      0.995      0.815\r\n",
      "\r\n",
      "2 epochs completed in 0.010 hours.\r\n",
      "Optimizer stripped from runs/train/exp66/weights/last.pt, 14.9MB\r\n",
      "Optimizer stripped from runs/train/exp66/weights/best.pt, 14.9MB\r\n",
      "\r\n",
      "Validating runs/train/exp66/weights/best.pt...\r\n",
      "Fusing layers... \r\n",
      "YOLOv5s summary: 157 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all          4          4      0.979          1      0.995      0.874\r\n",
      "                   cat          4          4      0.979          1      0.995      0.874\r\n",
      "Results saved to \u001B[1mruns/train/exp66\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 640 --epochs 2 --data custom_dataset/custom_dataset.yaml  --weights 'yolov5s.pt' --cfg yolov5s.yaml --hyp hyp/hyp.scratch-low.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-24T18:26:24.354575Z",
     "start_time": "2024-06-24T18:24:52.150182Z"
    }
   },
   "id": "547b836739fcfa6f",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!python val.py --weights runs/train/exp4/weights/last.pt --data custom_dataset/custom_dataset.yaml "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99f6bd5fffd4add6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "59dab99a6515a3e6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:00<00:00, 43.69it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 48.91it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2  # –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ OpenCV –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # –î–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞\n",
    "\n",
    "def add_gaussian_noise(image, mean=0, std=0.1):\n",
    "    \"\"\"–î–æ–±–∞–≤–ª—è–µ—Ç –≥–∞—É—Å—Å–æ–≤—Å–∫–∏–π —à—É–º –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é.\"\"\"\n",
    "    gauss = np.random.normal(mean, std, image.shape).astype('float32')\n",
    "    noisy_image = image + gauss\n",
    "    return np.clip(noisy_image, 0, 1)\n",
    "\n",
    "def add_salt_and_pepper_noise(image, salt_prob=0.01, pepper_prob=0.01):\n",
    "    \"\"\"–î–æ–±–∞–≤–ª—è–µ—Ç —à—É–º —Å–æ–ª–∏ –∏ –ø–µ—Ä—Ü–∞ –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é.\"\"\"\n",
    "    noisy_image = image.copy()\n",
    "    num_salt = np.ceil(salt_prob * image.size * 0.5)\n",
    "    num_pepper = np.ceil(pepper_prob * image.size * 0.5)\n",
    "\n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–ª—å\n",
    "    coords = [np.random.randint(0, i - 1, int(num_salt)) for i in image.shape]\n",
    "    noisy_image[tuple(coords)] = 1\n",
    "\n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–µ—Ü\n",
    "    coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in image.shape]\n",
    "    noisy_image[tuple(coords)] = 0\n",
    "\n",
    "    return noisy_image\n",
    "\n",
    "def process_directory(input_dir, output_dir, noise_type=\"gaussian\", noise_level=0.1):\n",
    "    \"\"\"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏, –¥–æ–±–∞–≤–ª—è—è —à—É–º –∏ —Å–æ—Ö—Ä–∞–Ω—è—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç.\"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for filename in tqdm(os.listdir(input_dir)):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(input_dir, filename)\n",
    "            image = cv2.imread(image_path).astype('float32') / 255.0  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n",
    "            if noise_type == \"gaussian\":\n",
    "                noisy_image = add_gaussian_noise(image, std=noise_level)\n",
    "            elif noise_type == \"salt_and_pepper\":\n",
    "                noisy_image = add_salt_and_pepper_noise(image, salt_prob=noise_level, pepper_prob=noise_level)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported noise type\")\n",
    "            \n",
    "            noisy_image = (noisy_image * 255).astype('uint8')  # –î–µ–Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n",
    "            output_path = os.path.join(output_dir, filename)\n",
    "            cv2.imwrite(output_path, noisy_image)\n",
    "\n",
    "# –ü—É—Ç–∏ –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º\n",
    "train_dir = 'custom_dataset/custom_dataset/images/train'\n",
    "val_dir = 'custom_dataset/custom_dataset/images/test'\n",
    "noisy_train_dir = 'custom_dataset/custom_dataset/images/noisy_train'\n",
    "noisy_val_dir = 'custom_dataset/custom_dataset/images/noisy_test'\n",
    "\n",
    "# –ó–∞—à—É–º–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "process_directory(train_dir, noisy_train_dir, noise_type=\"gaussian\", noise_level=0.1)\n",
    "process_directory(val_dir, noisy_val_dir, noise_type=\"gaussian\", noise_level=0.1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-24T21:05:03.259886Z",
     "start_time": "2024-06-24T21:05:02.231530Z"
    }
   },
   "id": "49041f7918266880",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cc003eefef07c1bf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
